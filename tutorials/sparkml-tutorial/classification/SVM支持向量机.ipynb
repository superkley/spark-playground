{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machines (SVMs)\n",
    "线性SVM是一个标准的大型分类任务，它是一种$ \\begin{equation}\n",
    "    f(v) := \\lambda\\, R(w) +\n",
    "    \\frac1n \\sum_{i=1}^n L(v;x_i,y_i)\n",
    "    \\label{eq:regPrimal}\n",
    "    \\ .\n",
    "\\end{equation} $ 的线性模型，损失函数如下：\n",
    "$$L(w;x,y) := \\max \\{0, 1-y w^T x \\}.$$ \n",
    "默认情况下SVM使用的是L2正则化，我们也可以设置成L1.  \n",
    "输入数据给分类器会输出一个类别标签，这相当于一个类似于Sigmoid的函数作用。模型的预测结果是基于 $ w^T x $的值，如果$ w^T x $ 如果大于0 输出＋1 否则输出－1.\n",
    "## Examples\n",
    "下面的代码演示如何加载数据集，我们通过调用SVMWithSGD对象的静态方法来训练测试数据集，并且计算预测误差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC = 1.0\n"
     ]
    }
   ],
   "source": [
    "val PATH = \"file:///Users/lzz/work/SparkML/\"\n",
    "import org.apache.spark.mllib.classification.{SVMModel, SVMWithSGD}\n",
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "import org.apache.spark.mllib.util.MLUtils\n",
    "\n",
    "// Load training data in LIBSVM format.\n",
    "val data = MLUtils.loadLibSVMFile(sc, PATH+\"data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "// Split data into training (60%) and test (40%).\n",
    "val splits = data.randomSplit(Array(0.6, 0.4), seed = 11L)\n",
    "val training = splits(0).cache()\n",
    "val test = splits(1)\n",
    "\n",
    "// Run training algorithm to build the model\n",
    "val numIterations = 100\n",
    "val model = SVMWithSGD.train(training, numIterations)\n",
    "\n",
    "// Clear the default threshold.\n",
    "model.clearThreshold()\n",
    "\n",
    "// Compute raw scores on the test set.\n",
    "val scoreAndLabels = test.map { point =>\n",
    "  val score = model.predict(point.features)\n",
    "  (score, point.label)\n",
    "}\n",
    "\n",
    "// Get evaluation metrics.\n",
    "val metrics = new BinaryClassificationMetrics(scoreAndLabels)\n",
    "val auROC = metrics.areaUnderROC()\n",
    "\n",
    "println(\"Area under ROC = \" + auROC)\n",
    "\n",
    "// Save and load model\n",
    "model.save(sc, \"myModelPath\")\n",
    "val sameModel = SVMModel.load(sc, \"myModelPath\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVMWithSGD.train() 该方法默认采用的是L2正则化。如果我们想配置这些算法，我们可以自定义 SVMWithSGD 进一步通过创建新对象直接调用setter方法。其它 MLlib 也是支持自定义配置方法也是一样的。例如，下面的代码设置 SVM 的正则化参数 0.1 并迭代 200 次运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.mllib.optimization.L1Updater\n",
    "\n",
    "val svmAlg = new SVMWithSGD()\n",
    "svmAlg.optimizer.\n",
    "  setNumIterations(200).\n",
    "  setRegParam(0.1).\n",
    "  setUpdater(new L1Updater)\n",
    "val modelL1 = svmAlg.run(training)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.5.2 (Scala 2.10)",
   "language": "",
   "name": "spark"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
