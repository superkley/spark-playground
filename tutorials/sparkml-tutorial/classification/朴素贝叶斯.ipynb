{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯(Naive Bayes)\n",
    "贝叶斯是一个简单的多分类算法，假设属性之间相互独立那么通过贝叶斯训练是很有效的。在训练集上去计算每个特征的条件概率分布值，应用贝叶斯定理计算条件概率分布的观察值并用于预测。  \n",
    "MLlib 支持多项式朴素贝叶斯和伯努力朴素贝叶斯，这些模型典型的被用于文档的分类。在该上下文中，每个观察是一个文档、每个特征代表一个词该值出现的频率叫词频（多项式朴素贝叶斯）或 着用 0 或 1 标识它在文档中是否出现（伯努利{0-1分布}朴素贝叶斯）。特征值必须是非负的。该模型的类型可以通过设置可选参数“multinomial（多项式）” 或 “bernoulli（伯努利）”、默认值是“多项式”。可以通过设置参数λ增加平滑度（默认值0.1）。对于文档分类，输入的特征向量通常是稀疏的，我们可以使用稀疏向量进行存储这样有利于节省空间。由于训练数据只使用一次，所以没必要缓存它。\n",
    "## 例子（Example）\n",
    "NaiveBayes 实现了多项式朴素贝叶斯。采用 LabeledPoint 的 RDD 数据和一个 lambda 作为输入参数，还有一个参数用于设置算法模型的（默认使用 多项式“multinomial”）,然后输出一个NaiveBayesModel 用于评估和预测。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name: Syntax Error.\n",
       "Message: \n",
       "StackTrace: "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val PATH = \"file:///Users/lzz/work/SparkML/\"\n",
    "\n",
    "import org.apache.spark.mllib.classification.{NaiveBayes, NaiveBayesModel}\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "import org.apache.spark.mllib.regression.LabeledPoint\n",
    "\n",
    "val data = sc.textFile(PATH+\"data/mllib/sample_naive_bayes_data.txt\")\n",
    "val parsedData = data.map { line =>\n",
    "  val parts = line.split(',')\n",
    "  LabeledPoint(parts(0).toDouble, Vectors.dense(parts(1).split(' ').map(_.toDouble)))\n",
    "}\n",
    "// Split data into training (60%) and test (40%).\n",
    "val splits = parsedData.randomSplit(Array(0.6, 0.4), seed = 11L)\n",
    "val training = splits(0)\n",
    "val test = splits(1)\n",
    "\n",
    "val model = NaiveBayes.train(training, lambda = 1.0, modelType = \"multinomial\")\n",
    "\n",
    "val predictionAndLabel = test.map(p => (model.predict(p.features), p.label))\n",
    "val accuracy = 1.0 * predictionAndLabel.filter(x => x._1 == x._2).count() / test.count()\n",
    "\n",
    "println( accuracy )\n",
    "// Save and load model\n",
    "// model.save(sc, \"myModelPath\")\n",
    "// val sameModel = NaiveBayesModel.load(sc, \"myModelPath\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.5.2 (Scala 2.10)",
   "language": "",
   "name": "spark"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
