{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElementwiseProduct\n",
    "ElementwiseProduct multiplies each input vector by a provided “weight” vector, using element-wise multiplication. In other words, it scales each column of the dataset by a scalar multiplier. This represents the Hadamard product between the input vector, v and transforming vector, w, to yield a result vector.\n",
    "$$ \\begin{pmatrix}\n",
    "v_1 \\\\\n",
    "\\vdots \\\\\n",
    "v_N\n",
    "\\end{pmatrix} \\circ \\begin{pmatrix}\n",
    "                    w_1 \\\\\n",
    "                    \\vdots \\\\\n",
    "                    w_N\n",
    "                    \\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "  v_1 w_1 \\\\\n",
    "  \\vdots \\\\\n",
    "  v_N w_N\n",
    "  \\end{pmatrix} $$\n",
    " \n",
    "ElementwiseProduct has the following parameter in the constructor:\n",
    "\n",
    "* w: the transforming vector.\n",
    "ElementwiseProduct implements VectorTransformer which can apply the weighting on a Vector to produce a transformed Vector or on an RDD[Vector] to produce a transformed RDD[Vector].\n",
    "\n",
    "## Example\n",
    "This example below demonstrates how to transform vectors using a transforming vector value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.mllib.feature.ElementwiseProduct\n",
    "import org.apache.spark.mllib.linalg.Vectors\n",
    "\n",
    "// Create some vector data; also works for sparse vectors\n",
    "val data = sc.parallelize(Array(Vectors.dense(1.0, 2.0, 3.0), Vectors.dense(4.0, 5.0, 6.0)))\n",
    "\n",
    "val transformingVector = Vectors.dense(0.0, 1.0, 2.0)\n",
    "val transformer = new ElementwiseProduct(transformingVector)\n",
    "\n",
    "// Batch transform and per-row transform give the same results:\n",
    "val transformedData = transformer.transform(data)\n",
    "val transformedData2 = data.map(x => transformer.transform(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark 1.5.2 (Scala 2.10)",
   "language": "",
   "name": "spark"
  },
  "language_info": {
   "name": "scala",
   "version": "2.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
